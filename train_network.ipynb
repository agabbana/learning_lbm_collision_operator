{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2471a3-b5f3-446d-b82b-76fe6e157359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad507b5-e401-41bc-a086-19d2ab3b6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set precision (default is 'float32')\n",
    "K.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca224c-02d9-4cad-b55b-f763cd49b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "\n",
    "    data = np.load(fname, allow_pickle=True)\n",
    "\n",
    "    feq   = data['f_eq']\n",
    "    fpre  = data['f_pre']\n",
    "    fpost = data['f_post']\n",
    "    \n",
    "    return feq, fpre, fpost\n",
    "\n",
    "def LBrot90(f, k=1):   \n",
    "    return tf.concat( [ f[:,0,None], tf.roll(f[:,1:5], k, axis=-1),  \n",
    "                                     tf.roll(f[:,5: ], k, axis=-1) \n",
    "                      ], axis=-1 )\n",
    "\n",
    "def LBmirror(f):\n",
    "    return tf.concat( [f[:,0, None], f[:,1, None], f[:,4, None], \n",
    "                       f[:,3, None], f[:,2, None], f[:,8, None], \n",
    "                       f[:,7, None], f[:,6, None], f[:,5, None]\n",
    "                       ], axis=-1 )\n",
    "\n",
    "class D4Symmetry(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(D4Symmetry, self).__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        y = [x               ,\n",
    "             LBrot90(x, k=1 ),\n",
    "             LBrot90(x, k=2 ),\n",
    "             LBrot90(x, k=3 ),\n",
    "             LBmirror(x               ),\n",
    "             LBmirror(LBrot90(x, k=1 )),\n",
    "             LBmirror(LBrot90(x, k=2 )),\n",
    "             LBmirror(LBrot90(x, k=3 ))]\n",
    "        \n",
    "        return y\n",
    "\n",
    "\n",
    "class D4AntiSymmetry(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(D4AntiSymmetry, self).__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        y = [x[0],\n",
    "             LBrot90(x[1], k=-1 ),\n",
    "             LBrot90(x[2], k=-2 ),\n",
    "             LBrot90(x[3], k=-3 ),\n",
    "             LBmirror(x[4])                ,\n",
    "             LBrot90(LBmirror(x[5]), k=-1 ),\n",
    "             LBrot90(LBmirror(x[6]), k=-2 ),\n",
    "             LBrot90(LBmirror(x[7]), k=-3 )]\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    \n",
    "class AlgReconstruction(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(AlgReconstruction, self).__init__()\n",
    "\n",
    "    def call(self, fpre, fpred):\n",
    "\n",
    "        df  = fpred - fpre\n",
    "\n",
    "        df2 =       -(df[:,0]+2*df[:,3]+  df[:,4]+2*df[:,6]+2*df[:,7])\n",
    "        df5 =    0.5*(df[:,0]+3*df[:,3]+2*df[:,4]+2*df[:,6]+4*df[:,7]-df[:,1])\n",
    "        df8 =   -0.5*(df[:,0]+  df[:,1]+  df[:,3]+2*df[:,4]+2*df[:,7])\n",
    "        \n",
    "        df = tf.concat( [ df[:, 0, None],\n",
    "                          df[:, 1, None],\n",
    "                          df2[:,None],\n",
    "                          df[:, 3, None],\n",
    "                          df[:, 4, None],\n",
    "                          df5[:,None],\n",
    "                          df[:, 6, None],\n",
    "                          df[:, 7, None],\n",
    "                          df8[:,None]\n",
    "                        ], axis=-1 ) \n",
    "\n",
    "        res = fpre + df\n",
    "\n",
    "        return res    \n",
    "    \n",
    "    \n",
    "# class AlgReconstructionSymm(tf.keras.layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super(AlgReconstructionSymm, self).__init__()\n",
    "\n",
    "#     def call(self, fpre, fpred, c):\n",
    "\n",
    "#         df  = fpred - fpre\n",
    "\n",
    "#         df_sum = tf.reduce_sum( df, axis=1 )\n",
    "        \n",
    "#         k1 = - (1./9.)*df_sum\n",
    "#         k2 = - (1./6.)*(tf.reduce_sum( df*c[:,0], axis=1 ) )\n",
    "#         k3 = - (1./6.)*(tf.reduce_sum( df*c[:,1], axis=1 ) )\n",
    "        \n",
    "#         res = fpred + k1[:,None] + k2[:,None]*c[:,0] + k3[:,None]*c[:,1]\n",
    "\n",
    "#         return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb81eed-daee-4ba6-b21a-dbaaf8a4a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_model(Q=9, n_hidden_layers=2, n_per_layer=50, activation=\"relu\", \n",
    "                     ll_activation=\"linear\", bias=False):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(n_per_layer, input_shape=(Q,), activation=activation, use_bias=bias, kernel_initializer = \"he_uniform\"))\n",
    "    \n",
    "    for jj in range(n_hidden_layers):\n",
    "        model.add(Dense(n_per_layer, activation=activation, use_bias=bias, kernel_initializer = \"he_uniform\"))\n",
    "    \n",
    "    model.add(Dense(Q, activation=ll_activation, use_bias=bias, kernel_initializer = \"he_uniform\"))\n",
    "\n",
    "    return model \n",
    "\n",
    "def create_model(loss=\"mape\", optimizer=\"adam\", Q=9, \n",
    "                 n_hidden_layers=2, n_per_layer=50, activation=\"relu\", \n",
    "                 ll_activation=\"linear\", bias=False):\n",
    "    \n",
    "    the_input = keras.Input(shape=(Q))\n",
    "\n",
    "    seq_model = sequential_model(Q, n_hidden_layers, n_per_layer, \n",
    "                                 ll_activation, ll_activation, bias)\n",
    "    \n",
    "    input_lst  = D4Symmetry()(the_input)\n",
    "    \n",
    "    output_lst = [seq_model(x) for k, x in enumerate(input_lst) ]\n",
    "\n",
    "    output_lst = [AlgReconstruction()(input_lst[k], x) for k, x in enumerate(output_lst) ] \n",
    "    # output_lst = [AlgReconstructionSymm()(input_lst[k], x, c) for k, x in enumerate(output_lst) ] \n",
    "\n",
    "    output_lst = D4AntiSymmetry()(output_lst)\n",
    "    \n",
    "    the_output = layers.Average()(output_lst)\n",
    "\n",
    "    model = keras.Model(inputs=the_input, outputs=the_output)\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer)    \n",
    "    \n",
    "    return(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b9998f-7f27-4f96-82c3-79aa2fe0bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# lattice velocities and weights\n",
    "# Needed if you want to use AlgReconstructionSymm\n",
    "# c, _, _, _ = LB_stencil()\n",
    "# c = np.array(c, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494244c5-629f-41a9-9d51-c782ed36918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training dataset\n",
    "feq, fpre, fpost = load_data('example_dataset.npz')\n",
    "\n",
    "# normalize data on density \n",
    "feq   = feq   / np.sum(feq,axis=1)[:,np.newaxis]\n",
    "fpre  = fpre  / np.sum(fpre,axis=1)[:,np.newaxis]\n",
    "fpost = fpost / np.sum(fpost,axis=1)[:,np.newaxis]\n",
    "\n",
    "# split train and test set\n",
    "fpre_train, fpre_test, fpost_train, fpost_test = train_test_split(fpre, fpost, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2862d5-f89b-43d9-b90b-68d1c5a84943",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "n_epochs=200\n",
    "patience=50\n",
    "verbose=1\n",
    "\n",
    "model = create_model(loss=rmsre, ll_activation=\"softmax\")\n",
    "\n",
    "# EarlyStopping\n",
    "es_callback = [EarlyStopping(monitor = \"val_loss\", patience = patience, restore_best_weights=True)]\n",
    "\n",
    "# Save weights on file when improving the validation loss\n",
    "ck_callback = ModelCheckpoint(filepath=\"weights.hdf5\", monitor = \"val_loss\", save_best_only=True)\n",
    "\n",
    "keras_callbacks = [es_callback, ck_callback]         \n",
    "\n",
    "## training the model\n",
    "hist = model.fit(fpre_train, fpost_train, \n",
    "                 epochs=n_epochs, verbose=verbose, callbacks=keras_callbacks, \n",
    "                 validation_data = (fpre_test, fpost_test), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c007283a-e427-4810-b5ed-184258996bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights.hdf5\")\n",
    "model.save(\"example_network.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db1364-6648-4e0a-9220-de8a3e8aed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(fpre_test, fpost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32991c58-fd7e-491d-9043-d5a9c41ad8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.semilogy( hist.history['loss']    , lw=3, label='Training'   )\n",
    "plt.semilogy( hist.history['val_loss'], lw=3, label='Validation' )\n",
    "\n",
    "plt.legend(loc='best', frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
